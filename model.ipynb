{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex        age  sibsp  parch  \\\n",
       "583           583         0       1    male  36.000000      0      0   \n",
       "337           337         1       1  female  41.000000      0      0   \n",
       "50             50         0       3    male   7.000000      4      1   \n",
       "218           218         1       1  female  32.000000      0      0   \n",
       "31             31         1       1  female  29.916875      1      0   \n",
       "\n",
       "         fare embarked  class  embark_town  alone  Q  S  \n",
       "583   40.1250        C  First    Cherbourg      1  0  0  \n",
       "337  134.5000        C  First    Cherbourg      1  0  0  \n",
       "50    39.6875        S  Third  Southampton      0  0  1  \n",
       "218   76.2917        C  First    Cherbourg      1  0  0  \n",
       "31   146.5208        C  First    Cherbourg      0  0  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepped titanic data: train, validate, test samples\n",
    "\n",
    "train, validate, test = prep_titanic()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    307\n",
      "1    190\n",
      "Name: survived, dtype: int64 \n",
      "\n",
      "Baseline Acccuracy: 0.6177062374245473\n"
     ]
    }
   ],
   "source": [
    "# baseline model: not survived is most common\n",
    "survived = train.survived.value_counts()\n",
    "print(survived, '\\n')\n",
    "\n",
    "# died/total passengers (accuracy)\n",
    "baseline_accuracy = survived[0]/survived.sum()\n",
    "print('Baseline Acccuracy:', baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03051881  0.00266519 -0.97983178]]\n",
      "Intercept: \n",
      " [2.52970125]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1: includes age, pclass, fare\n",
    "\n",
    "# A. create model object\n",
    "logit = LogisticRegression(C=1, class_weight=None, random_state=123)\n",
    "\n",
    "# B. split each sample into an X DataFrame and a Y Series\n",
    "X_train = train[['age', 'fare', 'pclass']]\n",
    "Y_train = train.survived\n",
    "\n",
    "X_validate = validate[['age', 'fare', 'pclass']]\n",
    "Y_validate = validate.survived\n",
    "\n",
    "X_test = test[['age', 'fare', 'pclass']]\n",
    "Y_test = test.survived\n",
    "\n",
    "# C. Fit to X and Y train\n",
    "logit = logit.fit(X_train, Y_train)\n",
    "\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.716297786720322 \n",
      "\n",
      "[[265  42]\n",
      " [ 99  91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       307\n",
      "           1       0.68      0.48      0.56       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.71      0.67      0.68       497\n",
      "weighted avg       0.71      0.72      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#D. Predict Values on X_train\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "\n",
    "#accuracy\n",
    "print('Accuracy: ', logit.score(X_train, Y_train), '\\n')\n",
    "\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_train, y_pred))\n",
    "\n",
    "#classification report\n",
    "print(classification_report(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex        age  sibsp  parch  \\\n",
       "583           583         0       1    male  36.000000      0      0   \n",
       "337           337         1       1  female  41.000000      0      0   \n",
       "50             50         0       3    male   7.000000      4      1   \n",
       "218           218         1       1  female  32.000000      0      0   \n",
       "31             31         1       1  female  29.916875      1      0   \n",
       "\n",
       "         fare embarked  class  embark_town  alone  Q  S  sex_male  \n",
       "583   40.1250        C  First    Cherbourg      1  0  0         1  \n",
       "337  134.5000        C  First    Cherbourg      1  0  0         0  \n",
       "50    39.6875        S  Third  Southampton      0  0  1         1  \n",
       "218   76.2917        C  First    Cherbourg      1  0  0         0  \n",
       "31   146.5208        C  First    Cherbourg      0  0  0         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy variable for sex as is_male\n",
    "train_dummies = pd.get_dummies(train[['sex']], drop_first=True)\n",
    "train = pd.concat([train, train_dummies], axis=1)\n",
    "\n",
    "validate_dummies = pd.get_dummies(validate[['sex']], drop_first=True)\n",
    "validate = pd.concat([validate, validate_dummies], axis=1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['sex']], drop_first=True)\n",
    "test = pd.concat([test, test_dummies], axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.66594879e-02  9.02716903e-04 -1.11402368e+00 -2.45878213e+00]]\n",
      "Intercept: \n",
      " [4.30664987]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: includes age, pclass, fare, sex\n",
    "\n",
    "# A. create model object\n",
    "logit2 = LogisticRegression(C=1, class_weight=None, random_state=123)\n",
    "\n",
    "# B. split each sample into an X DataFrame and a Y Series\n",
    "X_train2 = train[['age', 'fare', 'pclass', 'sex_male']]\n",
    "Y_train2 = train.survived\n",
    "\n",
    "X_validate2 = validate[['age', 'fare', 'pclass', 'sex_male']]\n",
    "Y_validate2 = validate.survived\n",
    "\n",
    "X_test2 = test[['age', 'fare', 'pclass', 'sex_male']]\n",
    "Y_test2 = test.survived\n",
    "\n",
    "# C. Fit to X and Y train\n",
    "logit2 = logit2.fit(X_train2, Y_train2)\n",
    "\n",
    "print('Coefficient: \\n', logit2.coef_)\n",
    "print('Intercept: \\n', logit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7987927565392354 \n",
      "\n",
      "[[263  44]\n",
      " [ 56 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.71      0.73       190\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.79      0.78      0.78       497\n",
      "weighted avg       0.80      0.80      0.80       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#D. Predict Values on X_train\n",
    "y_pred2 = logit2.predict(X_train2)\n",
    "y_pred_proba2 = logit2.predict_proba(X_train2)\n",
    "\n",
    "#accuracy\n",
    "print('Accuracy: ', logit2.score(X_train2, Y_train2), '\\n')\n",
    "\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_train2, y_pred2))\n",
    "\n",
    "#classification report\n",
    "print(classification_report(Y_train2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.55633270e-02  5.53491876e-04 -1.10859199e+00 -2.41546062e+00\n",
      "  -1.58214588e-01]]\n",
      "Intercept: \n",
      " [4.33705386]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: includes age, pclass, fare, sex, and alone\n",
    "\n",
    "# A. create model object\n",
    "logit3 = LogisticRegression(C=1, class_weight=None, random_state=123)\n",
    "\n",
    "# B. split each sample into an X DataFrame and a Y Series\n",
    "X_train3 = train[['age', 'fare', 'pclass', 'sex_male', 'alone']]\n",
    "Y_train3 = train.survived\n",
    "\n",
    "X_validate3 = validate[['age', 'fare', 'pclass', 'sex_male', 'alone']]\n",
    "Y_validate3 = validate.survived\n",
    "\n",
    "X_test3 = test[['age', 'fare', 'pclass', 'sex_male', 'alone']]\n",
    "Y_test3 = test.survived\n",
    "\n",
    "# C. Fit to X and Y train\n",
    "logit3 = logit3.fit(X_train3, Y_train3)\n",
    "\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7967806841046278 \n",
      "\n",
      "[[263  44]\n",
      " [ 57 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.70      0.72       190\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.79      0.78      0.78       497\n",
      "weighted avg       0.79      0.80      0.80       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#D. Predict Values on X_train\n",
    "y_pred3 = logit3.predict(X_train3)\n",
    "y_pred_proba3 = logit3.predict_proba(X_train3)\n",
    "\n",
    "#accuracy\n",
    "print('Accuracy: ', logit3.score(X_train3, Y_train3), '\\n')\n",
    "\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_train3, y_pred3))\n",
    "\n",
    "#classification report\n",
    "print(classification_report(Y_train3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      " 0.7289719626168224\n",
      "model 2\n",
      " 0.7850467289719626\n",
      "model 3\n",
      " 0.7850467289719626\n"
     ]
    }
   ],
   "source": [
    "# Validate Accuracy\n",
    "y_pred = logit.predict(X_validate)\n",
    "y_pred2 = logit2.predict(X_validate2)\n",
    "y_pred3 = logit3.predict(X_validate3)\n",
    "\n",
    "print(\"model 1\\n\", logit.score(X_validate, Y_validate))\n",
    "print(\"model 2\\n\", logit2.score(X_validate2, Y_validate2))\n",
    "print(\"model 3\\n\", logit3.score(X_validate3, Y_validate3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      " [[116  16]\n",
      " [ 42  40]]\n",
      "model 2\n",
      " [[111  21]\n",
      " [ 25  57]]\n",
      "model 3\n",
      " [[110  22]\n",
      " [ 24  58]]\n"
     ]
    }
   ],
   "source": [
    "# Validate Confusion Matrix\n",
    "print(\"model 1\\n\", confusion_matrix(Y_validate, y_pred))\n",
    "print(\"model 2\\n\", confusion_matrix(Y_validate2, y_pred2))\n",
    "print(\"model 3\\n\", confusion_matrix(Y_validate3, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       132\n",
      "           1       0.71      0.49      0.58        82\n",
      "\n",
      "    accuracy                           0.73       214\n",
      "   macro avg       0.72      0.68      0.69       214\n",
      "weighted avg       0.73      0.73      0.72       214\n",
      "\n",
      "model 2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       132\n",
      "           1       0.73      0.70      0.71        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.77      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "model 3\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       132\n",
      "           1       0.72      0.71      0.72        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.77      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate Classification Report\n",
    "print(\"model 1\\n\", classification_report(Y_validate, y_pred))\n",
    "print(\"model 2\\n\", classification_report(Y_validate2, y_pred2))\n",
    "print(\"model 3\\n\", classification_report(Y_validate3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3: solver = lbfgs, c = 1\n",
      "Accuracy: 0.81\n",
      "[[92 18]\n",
      " [16 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       110\n",
      "           1       0.74      0.76      0.75        68\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.80      0.80      0.80       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = logit3.predict(X_test3)\n",
    "y_pred_proba3 = logit3.predict_proba(X_test3)\n",
    "\n",
    "print(\"Model 3: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit3.score(X_test3, Y_test3)))\n",
    "\n",
    "print(confusion_matrix(Y_test3, y_pred3))\n",
    "\n",
    "print(classification_report(Y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['passenger_id', 'sex', 'embark_town', 'embarked', 'class', 'survived'])\n",
    "y_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=123, splitter='best'),\n",
       " array([0, 1, 0, 1, 1]),\n",
       " array([[0.51666667, 0.48333333],\n",
       "        [0.0326087 , 0.9673913 ],\n",
       "        [0.88      , 0.12      ],\n",
       "        [0.0326087 , 0.9673913 ],\n",
       "        [0.0326087 , 0.9673913 ]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit model to training data\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Estimate Survived\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "# Estimate probability of survived\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "\n",
    "clf, y_pred[:5], y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "acc = round(clf.score(X_train, y_train),2)\n",
    "\n",
    "# Create Confustion Matrix\n",
    "labels = sorted(y_train.survived.unique())\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0][0]\n",
    "FN = cm[0][1]\n",
    "FP = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+TN)\n",
    "TNR = TN/(TN+FP)\n",
    "FNR = FN/(FN+TP)\n",
    "\n",
    "# Create Classification Report\n",
    "cr = classification_report(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82 \n",
      "\n",
      "True Positive Rate:  0.8181818181818182 \n",
      "\n",
      "False Positive Rate:  0.1794871794871795 \n",
      "\n",
      "True Negative Rate:  0.8205128205128205 \n",
      "\n",
      "False Negative Rate:  0.18181818181818182 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       307\n",
      "           1       0.82      0.67      0.74       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.79      0.80       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      "\n",
      "Confustion Matrix: \n",
      "      0    1\n",
      "0  279   28\n",
      "1   62  128\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', acc, '\\n')\n",
    "print('True Positive Rate: ', TPR,  '\\n')\n",
    "print('False Positive Rate: ', FPR, '\\n')\n",
    "print('True Negative Rate: ', TNR, '\\n')\n",
    "print('False Negative Rate: ', FNR, '\\n')\n",
    "print('Classification Report: \\n', cr)\n",
    "print('Confustion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=123, splitter='best'),\n",
       " array([0, 1, 0, 1, 1]),\n",
       " array([[0.60416667, 0.39583333],\n",
       "        [0.        , 1.        ],\n",
       "        [0.87777778, 0.12222222],\n",
       "        [0.        , 1.        ],\n",
       "        [0.        , 1.        ]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Object\n",
    "clf2 = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "\n",
    "# Fit model to training data\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "#Estimate Survived\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "\n",
    "# Estimate probability of survived\n",
    "y_pred_proba2 = clf2.predict_proba(X_train)\n",
    "\n",
    "clf2, y_pred2[:5], y_pred_proba2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  285   22\n",
       "1   49  141"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "acc2 = round(clf2.score(X_train, y_train),2)\n",
    "\n",
    "# Create Confustion Matrix\n",
    "labels2 = sorted(y_train.survived.unique())\n",
    "\n",
    "cm2 = pd.DataFrame(confusion_matrix(y_train, y_pred2), index=labels, columns=labels)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP2 = cm2[0][0]\n",
    "FN2 = cm2[0][1]\n",
    "FP2 = cm2[1][0]\n",
    "TN2 = cm2[1][1]\n",
    "\n",
    "TPR2 = TP2/(TP2+FN2)\n",
    "FPR2 = FP2/(FP2+TN2)\n",
    "TNR2 = TN2/(TN2+FP2)\n",
    "FNR2 = FN2/(FN2+TP2)\n",
    "\n",
    "# Create Classification Report\n",
    "cr2 = classification_report(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2:  0.86 \n",
      "\n",
      "True Positive Rate 2:  0.8532934131736527 \n",
      "\n",
      "False Positive Rate 2:  0.13496932515337423 \n",
      "\n",
      "True Negative Rate 2:  0.8650306748466258 \n",
      "\n",
      "False Negative Rate 2:  0.1467065868263473 \n",
      "\n",
      "Classification Report 2: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       307\n",
      "           1       0.87      0.74      0.80       190\n",
      "\n",
      "    accuracy                           0.86       497\n",
      "   macro avg       0.86      0.84      0.84       497\n",
      "weighted avg       0.86      0.86      0.85       497\n",
      "\n",
      "Confustion Matrix 2: \n",
      "      0    1\n",
      "0  285   22\n",
      "1   49  141\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy 2: ', acc2, '\\n'),\n",
    "print('True Positive Rate 2: ', TPR2,  '\\n')\n",
    "print('False Positive Rate 2: ', FPR2, '\\n')\n",
    "print('True Negative Rate 2: ', TNR2, '\\n')\n",
    "print('False Negative Rate 2: ', FNR2, '\\n')\n",
    "print('Classification Report 2: \\n', cr2),\n",
    "print('Confustion Matrix 2: \\n', cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True Postive Rate</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.853293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positive Rate</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.134969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Negative Rate</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.865031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False Negative Rate</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.146707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Results   Model 1   Model 2\n",
       "0             Accuracy  0.820000  0.860000\n",
       "1    True Postive Rate  0.818182  0.853293\n",
       "2  False Positive Rate  0.179487  0.134969\n",
       "3   True Negative Rate  0.820513  0.865031\n",
       "4  False Negative Rate  0.181818  0.146707"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Results': ['Accuracy', \n",
    "                 'True Postive Rate', \n",
    "                 'False Positive Rate', \n",
    "                 'True Negative Rate', \n",
    "                 'False Negative Rate'], \n",
    "     'Model 1': [acc, TPR, FPR, TNR, FNR], \n",
    "     'Model 2':[acc2, TPR2, FPR2, TNR2, FNR2]\n",
    "    }\n",
    "\n",
    "best_model = pd.DataFrame(data=d)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       307\n",
      "           1       0.82      0.67      0.74       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.79      0.80       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      " \n",
      " Model 2: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       307\n",
      "           1       0.87      0.74      0.80       190\n",
      "\n",
      "    accuracy                           0.86       497\n",
      "   macro avg       0.86      0.84      0.84       497\n",
      "weighted avg       0.86      0.86      0.85       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1: \\n', cr, '\\n', 'Model 2: \\n', cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(clf,                        \n",
    "                           feature_names= X_train.columns,                      \n",
    "                           class_names= {0:'not survived', 1:'survived'},                         \n",
    "                           rounded=True,   \n",
    "                           filled=True,                         \n",
    "                           out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest object\n",
    "rf = RandomForestClassifier(max_depth=20, \n",
    "                            min_samples_leaf=2, \n",
    "                            random_state=123)\n",
    "#fit to the train data\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "#predict survival based on rf model\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "#predict probability survival based on rf model\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = rf.score(X_train, y_train)\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "cr = classification_report(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0][0]\n",
    "FN = cm[0][1]\n",
    "FP = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+TN)\n",
    "TNR = TN/(TN+FP)\n",
    "FNR = FN/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST: MODEL 1 \n",
      "\n",
      "Accuracy:  0.9356136820925554 \n",
      "\n",
      "True Positive Rate:  0.9771986970684039 \n",
      "\n",
      "False Positive Rate:  0.13157894736842105 \n",
      "\n",
      "True Negative Rate:  0.868421052631579 \n",
      "\n",
      "False Negative Rate:  0.02280130293159609 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       307\n",
      "           1       0.96      0.87      0.91       190\n",
      "\n",
      "    accuracy                           0.94       497\n",
      "   macro avg       0.94      0.92      0.93       497\n",
      "weighted avg       0.94      0.94      0.93       497\n",
      "\n",
      "Confusion Matrix: \n",
      " [[300   7]\n",
      " [ 25 165]]\n"
     ]
    }
   ],
   "source": [
    "print('RANDOM FOREST: MODEL 1 \\n')\n",
    "print('Accuracy: ', acc, '\\n')\n",
    "print('True Positive Rate: ', TPR,  '\\n')\n",
    "print('False Positive Rate: ', FPR, '\\n')\n",
    "print('True Negative Rate: ', TNR, '\\n')\n",
    "print('False Negative Rate: ', FNR, '\\n')\n",
    "print('Classification Report: \\n', cr)\n",
    "print('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest object\n",
    "rf2 = RandomForestClassifier(max_depth=3, \n",
    "                            min_samples_leaf=5, \n",
    "                            random_state=123)\n",
    "#fit to the train data\n",
    "rf2 = rf2.fit(X_train, y_train)\n",
    "\n",
    "#predict survival based on rf model\n",
    "y_pred2 = rf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = rf2.score(X_train, y_train)\n",
    "\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "\n",
    "cr2 = classification_report(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP2 = cm2[0][0]\n",
    "FN2 = cm2[0][1]\n",
    "FP2 = cm2[1][0]\n",
    "TN2 = cm2[1][1]\n",
    "\n",
    "TPR2 = TP2/(TP2+FN2)\n",
    "FPR2 = FP2/(FP2+TN2)\n",
    "TNR2 = TN2/(TN2+FP2)\n",
    "FNR2 = FN2/(FN2+TP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST: MODEL 2 \n",
      "\n",
      "Accuracy:  0.8309859154929577 \n",
      "\n",
      "True Positive Rate:  0.9381107491856677 \n",
      "\n",
      "False Positive Rate:  0.34210526315789475 \n",
      "\n",
      "True Negative Rate:  0.6578947368421053 \n",
      "\n",
      "False Negative Rate:  0.06188925081433225 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.87      0.66      0.75       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.84      0.80      0.81       497\n",
      "weighted avg       0.84      0.83      0.83       497\n",
      "\n",
      "Confusion Matrix: \n",
      " [[288  19]\n",
      " [ 65 125]]\n"
     ]
    }
   ],
   "source": [
    "print('RANDOM FOREST: MODEL 2 \\n')\n",
    "print('Accuracy: ', acc2, '\\n')\n",
    "print('True Positive Rate: ', TPR2,  '\\n')\n",
    "print('False Positive Rate: ', FPR2, '\\n')\n",
    "print('True Negative Rate: ', TNR2, '\\n')\n",
    "print('False Negative Rate: ', FNR2, '\\n')\n",
    "print('Classification Report: \\n', cr2)\n",
    "print('Confusion Matrix: \\n', cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.935614</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True Postive Rate</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.938111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positive Rate</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Negative Rate</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False Negative Rate</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.061889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Results   Model 1   Model 2\n",
       "0             Accuracy  0.935614  0.830986\n",
       "1    True Postive Rate  0.977199  0.938111\n",
       "2  False Positive Rate  0.131579  0.342105\n",
       "3   True Negative Rate  0.868421  0.657895\n",
       "4  False Negative Rate  0.022801  0.061889"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Results': ['Accuracy', \n",
    "                 'True Postive Rate', \n",
    "                 'False Positive Rate', \n",
    "                 'True Negative Rate', \n",
    "                 'False Negative Rate'], \n",
    "     'Model 1': [acc, TPR, FPR, TNR, FNR], \n",
    "     'Model 2':[acc2, TPR2, FPR2, TNR2, FNR2]\n",
    "    }\n",
    "\n",
    "best_model = pd.DataFrame(data=d)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (min_samples_leaf = 1, max_depth = 20): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       307\n",
      "           1       0.96      0.87      0.91       190\n",
      "\n",
      "    accuracy                           0.94       497\n",
      "   macro avg       0.94      0.92      0.93       497\n",
      "weighted avg       0.94      0.94      0.93       497\n",
      " \n",
      " Model 2 (min_samples_leaf = 5, max_depth = 3): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.87      0.66      0.75       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.84      0.80      0.81       497\n",
      "weighted avg       0.84      0.83      0.83       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 (min_samples_leaf = 1, max_depth = 20): \\n', cr, '\\n', 'Model 2 (min_samples_leaf = 5, max_depth = 3): \\n', cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 has better evaluation metrics because it has more depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create KNN object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn = knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = knn.score(X_train, y_train)\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "cr = classification_report(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0][0]\n",
    "FN = cm[0][1]\n",
    "FP = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+TN)\n",
    "TNR = TN/(TN+FP)\n",
    "FNR = FN/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: MODEL 1 \n",
      "\n",
      "Accuracy:  0.7746478873239436 \n",
      "\n",
      "True Positive Rate:  0.8338762214983714 \n",
      "\n",
      "False Positive Rate:  0.32105263157894737 \n",
      "\n",
      "True Negative Rate:  0.6789473684210526 \n",
      "\n",
      "False Negative Rate:  0.16612377850162866 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       307\n",
      "           1       0.72      0.68      0.70       190\n",
      "\n",
      "    accuracy                           0.77       497\n",
      "   macro avg       0.76      0.76      0.76       497\n",
      "weighted avg       0.77      0.77      0.77       497\n",
      "\n",
      "Confusion Matrix: \n",
      " [[256  51]\n",
      " [ 61 129]]\n"
     ]
    }
   ],
   "source": [
    "print('KNN: MODEL 1 \\n')\n",
    "print('Accuracy: ', acc, '\\n')\n",
    "print('True Positive Rate: ', TPR,  '\\n')\n",
    "print('False Positive Rate: ', FPR, '\\n')\n",
    "print('True Negative Rate: ', TNR, '\\n')\n",
    "print('False Negative Rate: ', FNR, '\\n')\n",
    "print('Classification Report: \\n', cr)\n",
    "print('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn2 = knn2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = knn2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = knn2.score(X_train, y_train)\n",
    "\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "\n",
    "cr2 = classification_report(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP2 = cm2[0][0]\n",
    "FN2 = cm2[0][1]\n",
    "FP2 = cm2[1][0]\n",
    "TN2 = cm2[1][1]\n",
    "\n",
    "TPR2 = TP2/(TP2+FN2)\n",
    "FPR2 = FP2/(FP2+TN2)\n",
    "TNR2 = TN2/(TN2+FP2)\n",
    "FNR2 = FN2/(FN2+TP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: MODEL 2 \n",
      "\n",
      "Accuracy:  0.7605633802816901 \n",
      "\n",
      "True Positive Rate:  0.9185667752442996 \n",
      "\n",
      "False Positive Rate:  0.49473684210526314 \n",
      "\n",
      "True Negative Rate:  0.5052631578947369 \n",
      "\n",
      "False Negative Rate:  0.08143322475570032 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       307\n",
      "           1       0.79      0.51      0.62       190\n",
      "\n",
      "    accuracy                           0.76       497\n",
      "   macro avg       0.77      0.71      0.72       497\n",
      "weighted avg       0.77      0.76      0.75       497\n",
      "\n",
      "Confusion Matrix: \n",
      " [[282  25]\n",
      " [ 94  96]]\n"
     ]
    }
   ],
   "source": [
    "print('KNN: MODEL 2 \\n')\n",
    "print('Accuracy: ', acc2, '\\n')\n",
    "print('True Positive Rate: ', TPR2,  '\\n')\n",
    "print('False Positive Rate: ', FPR2, '\\n')\n",
    "print('True Negative Rate: ', TNR2, '\\n')\n",
    "print('False Negative Rate: ', FNR2, '\\n')\n",
    "print('Classification Report: \\n', cr2)\n",
    "print('Confusion Matrix: \\n', cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "knn3 = knn3.fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = knn3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = knn3.score(X_train, y_train)\n",
    "\n",
    "cm3 = confusion_matrix(y_train, y_pred3)\n",
    "\n",
    "cr3 = classification_report(y_train, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP3 = cm2[0][0]\n",
    "FN3 = cm2[0][1]\n",
    "FP3 = cm2[1][0]\n",
    "TN3 = cm2[1][1]\n",
    "\n",
    "TPR3 = TP3/(TP3+FN3)\n",
    "FPR3 = FP3/(FP3+TN3)\n",
    "TNR3 = TN3/(TN3+FP3)\n",
    "FNR3 = FN3/(FN3+TP3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: MODEL 3 \n",
      "\n",
      "Accuracy:  0.7183098591549296 \n",
      "\n",
      "True Positive Rate:  0.9185667752442996 \n",
      "\n",
      "False Positive Rate:  0.49473684210526314 \n",
      "\n",
      "True Negative Rate:  0.5052631578947369 \n",
      "\n",
      "False Negative Rate:  0.08143322475570032 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       307\n",
      "           1       0.72      0.43      0.54       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.72      0.66      0.67       497\n",
      "weighted avg       0.72      0.72      0.70       497\n",
      "\n",
      "Confusion Matrix: \n",
      " [[276  31]\n",
      " [109  81]]\n"
     ]
    }
   ],
   "source": [
    "print('KNN: MODEL 3 \\n')\n",
    "print('Accuracy: ', acc3, '\\n')\n",
    "print('True Positive Rate: ', TPR3,  '\\n')\n",
    "print('False Positive Rate: ', FPR3, '\\n')\n",
    "print('True Negative Rate: ', TNR3, '\\n')\n",
    "print('False Negative Rate: ', FNR3, '\\n')\n",
    "print('Classification Report: \\n', cr3)\n",
    "print('Confusion Matrix: \\n', cm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True Postive Rate</td>\n",
       "      <td>0.833876</td>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.918567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positive Rate</td>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.494737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Negative Rate</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.505263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False Negative Rate</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Results   Model 1   Model 2   Model 3\n",
       "0             Accuracy  0.774648  0.760563  0.718310\n",
       "1    True Postive Rate  0.833876  0.918567  0.918567\n",
       "2  False Positive Rate  0.321053  0.494737  0.494737\n",
       "3   True Negative Rate  0.678947  0.505263  0.505263\n",
       "4  False Negative Rate  0.166124  0.081433  0.081433"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Results': ['Accuracy', \n",
    "                 'True Postive Rate', \n",
    "                 'False Positive Rate', \n",
    "                 'True Negative Rate', \n",
    "                 'False Negative Rate'], \n",
    "     'Model 1': [acc, TPR, FPR, TNR, FNR], \n",
    "     'Model 2':[acc2, TPR2, FPR2, TNR2, FNR2],\n",
    "     'Model 3': [acc3, TPR3, FPR3, TNR3, FNR3]\n",
    "    }\n",
    "\n",
    "best_model = pd.DataFrame(data=d)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (k=5): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       307\n",
      "           1       0.72      0.68      0.70       190\n",
      "\n",
      "    accuracy                           0.77       497\n",
      "   macro avg       0.76      0.76      0.76       497\n",
      "weighted avg       0.77      0.77      0.77       497\n",
      " \n",
      " Model 2 (k=10): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       307\n",
      "           1       0.79      0.51      0.62       190\n",
      "\n",
      "    accuracy                           0.76       497\n",
      "   macro avg       0.77      0.71      0.72       497\n",
      "weighted avg       0.77      0.76      0.75       497\n",
      " \n",
      " Model 3 (k=20): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       307\n",
      "           1       0.72      0.43      0.54       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.72      0.66      0.67       497\n",
      "weighted avg       0.72      0.72      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 (k=5): \\n', cr, '\\n', \n",
    "      'Model 2 (k=10): \\n', cr2, '\\n',\n",
    "      'Model 3 (k=20): \\n', cr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 takes the lead, they look very similar \n",
    "# with k=5 as a smaller source of data points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**\n",
    "\n",
    "For both the iris and the titanic data,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new dataframe with top 4 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Titanic Data\n",
    "    - Create a feature named who, this should be either man, woman, or child. How does including this feature affect your model's performance?\n",
    "    - Create a feature named adult_male that is either a 1 or a 0. How does this affect your model's predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iris Data\n",
    "    - Create features named petal_area and sepal_area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
